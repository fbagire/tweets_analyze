{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "different-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "from importlib import reload\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import string\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documented-violence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS.update([\"a\",\"will\",\"el\",\"del\",\"lo\", \"abord\", \"absolument\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ailleurs\", \"ainsi\", \"ait\", \"allaient\", \"allo\",\n",
    " \"allons\", \"all√¥\", \"alors\", \"anterieur\", \"anterieure\", \"anterieures\", \"apres\", \"apr√®s\", \"as\", \"assez\", \"attendu\", \"au\",\n",
    " \"aucun\", \"aucune\", \"aucuns\", \"aujourd\", \"aujourd'hui\", \"aupres\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\",\n",
    " \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autant\", \"autre\", \"autrefois\",\n",
    " \"autrement\", \"autres\", \"autrui\", \"aux\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\",\n",
    " \"aviez\", \"avions\", \"avoir\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"bas\", \"basee\", \"bat\", \"beau\", \"beaucoup\",\n",
    " \"bien\", \"bigre\", \"bon\", \"boum\", \"bravo\", \"brrr\", \"c\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-l√†\",\n",
    " \"celles\", \"celles-ci\", \"celles-l√†\", \"celui\", \"celui-ci\", \"celui-l√†\", \"cel√†\", \"cent\", \"cependant\", \"certain\",\n",
    " \"certaine\", \"certaines\", \"certains\", \"certes\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-l√†\", \"chacun\",\n",
    " \"chacune\", \"chaque\", \"cher\", \"chers\", \"chez\", \"chiche\", \"chut\", \"ch√®re\", \"ch√®res\", \"ci\", \"cinq\", \"cinquantaine\",\n",
    " \"cinquante\", \"cinquanti√®me\", \"cinqui√®me\", \"clac\", \"clic\", \"combien\", \"comme\", \"comment\", \"comparable\", \"comparables\",\n",
    " \"compris\", \"concernant\", \"contre\", \"couic\", \"crac\", \"d\", \"da\", \"dans\", \"de\", \"debout\", \"dedans\", \"dehors\", \"deja\",\n",
    " \"del√†\", \"depuis\", \"dernier\", \"derniere\", \"derriere\", \"derri√®re\", \"des\", \"desormais\", \"desquelles\", \"desquels\",\n",
    " \"dessous\", \"dessus\", \"deux\", \"deuxi√®me\", \"deuxi√®mement\", \"devant\", \"devers\", \"devra\", \"devrait\", \"different\",\n",
    " \"differentes\", \"differents\", \"diff√©rent\", \"diff√©rente\", \"diff√©rentes\", \"diff√©rents\", \"dire\", \"directe\", \"directement\",\n",
    " \"dit\", \"dite\", \"dits\", \"divers\", \"diverse\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dixi√®me\", \"doit\",\n",
    " \"doivent\", \"donc\", \"dont\", \"dos\", \"douze\", \"douzi√®me\", \"dring\", \"droite\", \"du\", \"duquel\", \"durant\", \"d√®s\", \"d√©but\",\n",
    " \"d√©sormais\", \"e\", \"effet\", \"egale\", \"egalement\", \"egales\", \"eh\", \"elle\", \"elle-m√™me\", \"elles\", \"elles-m√™mes\", \"en\",\n",
    " \"encore\", \"enfin\", \"entre\", \"envers\", \"environ\", \"es\", \"essai\", \"est\", \"et\", \"etant\", \"etc\", \"etre\", \"eu\", \"eue\",\n",
    " \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eux-m√™mes\",\n",
    " \"exactement\", \"except√©\", \"extenso\", \"exterieur\", \"e√ªmes\", \"e√ªt\", \"e√ªtes\", \"f\", \"fais\", \"faisaient\", \"faisant\", \"fait\",\n",
    " \"faites\", \"fa√ßon\", \"feront\", \"fi\", \"flac\", \"floc\", \"fois\", \"font\", \"force\", \"furent\", \"fus\", \"fusse\", \"fussent\",\n",
    " \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"f√ªmes\", \"f√ªt\", \"f√ªtes\", \"g\", \"gens\", \"h\", \"ha\", \"haut\", \"hein\", \"hem\", \"hep\",\n",
    " \"hi\", \"ho\", \"hol√†\", \"hop\", \"hormis\", \"hors\", \"hou\", \"houp\", \"hue\", \"hui\", \"huit\", \"huiti√®me\", \"hum\", \"hurrah\", \"h√©\",\n",
    " \"h√©las\", \"i\", \"ici\", \"il\", \"ils\", \"importe\", \"j\", \"je\", \"jusqu\", \"jusque\", \"juste\", \"k\", \"l\", \"la\", \"laisser\",\n",
    " \"laquelle\", \"las\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"longtemps\", \"lors\", \"lorsque\",\n",
    " \"lui\", \"lui-meme\", \"lui-m√™me\", \"l√†\", \"l√®s\", \"m\", \"ma\", \"maint\", \"maintenant\", \"mais\", \"malgre\", \"malgr√©\", \"maximale\",\n",
    " \"me\", \"meme\", \"memes\", \"merci\", \"mes\", \"mien\", \"mienne\", \"miennes\", \"miens\", \"mille\", \"mince\", \"mine\", \"minimale\",\n",
    " \"moi\", \"moi-meme\", \"moi-m√™me\", \"moindres\", \"moins\", \"mon\", \"mot\", \"moyennant\", \"multiple\", \"multiples\", \"m√™me\",\n",
    " \"m√™mes\", \"n\", \"na\", \"naturel\", \"naturelle\", \"naturelles\", \"ne\", \"neanmoins\", \"necessaire\", \"necessairement\", \"neuf\",\n",
    " \"neuvi√®me\", \"ni\", \"nombreuses\", \"nombreux\", \"nomm√©s\", \"non\", \"nos\", \"notamment\", \"notre\", \"nous\", \"nous-m√™mes\",\n",
    " \"nouveau\", \"nouveaux\", \"nul\", \"n√©anmoins\", \"n√¥tre\", \"n√¥tres\", \"o\", \"oh\", \"oh√©\", \"oll√©\", \"ol√©\", \"on\", \"ont\", \"onze\",\n",
    " \"onzi√®me\", \"ore\", \"ou\", \"ouf\", \"ouias\", \"oust\", \"ouste\", \"outre\", \"ouvert\", \"ouverte\", \"ouverts\", \"o|\", \"o√π\", \"p\",\n",
    " \"paf\", \"pan\", \"par\", \"parce\", \"parfois\", \"parle\", \"parlent\", \"parler\", \"parmi\", \"parole\", \"parseme\", \"partant\",\n",
    " \"particulier\", \"particuli√®re\", \"particuli√®rement\", \"pas\", \"pass√©\", \"pendant\", \"pense\", \"permet\", \"personne\",\n",
    " \"personnes\", \"peu\", \"peut\", \"peuvent\", \"peux\", \"pff\", \"pfft\", \"pfut\", \"pif\", \"pire\", \"pi√®ce\", \"plein\", \"plouf\",\n",
    " \"plupart\", \"plus\", \"plusieurs\", \"plut√¥t\", \"possessif\", \"possessifs\", \"possible\", \"possibles\", \"pouah\", \"pour\",\n",
    " \"pourquoi\", \"pourrais\", \"pourrait\", \"pouvait\", \"prealable\", \"precisement\", \"premier\", \"premi√®re\", \"premi√®rement\",\n",
    " \"pres\", \"probable\", \"probante\", \"procedant\", \"proche\", \"pr√®s\", \"psitt\", \"pu\", \"puis\", \"puisque\", \"pur\", \"pure\", \"q\",\n",
    " \"qu\", \"quand\", \"quant\", \"quant-√†-soi\", \"quanta\", \"quarante\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatri√®me\",\n",
    " \"quatri√®mement\", \"que\", \"quel\", \"quelconque\", \"quelle\", \"quelles\", \"quelqu'un\", \"quelque\", \"quelques\", \"quels\", \"qui\",\n",
    " \"quiconque\", \"quinze\", \"quoi\", \"quoique\", \"r\", \"rare\", \"rarement\", \"rares\", \"relative\", \"relativement\", \"remarquable\",\n",
    " \"rend\", \"rendre\", \"restant\", \"reste\", \"restent\", \"restrictif\", \"retour\", \"revoici\", \"revoil√†\", \"rien\", \"s\", \"sa\",\n",
    " \"sacrebleu\", \"sait\", \"sans\", \"sapristi\", \"sauf\", \"se\", \"sein\", \"seize\", \"selon\", \"semblable\", \"semblaient\", \"semble\",\n",
    " \"semblent\", \"sent\", \"sept\", \"septi√®me\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\",\n",
    " \"serions\", \"serons\", \"seront\", \"ses\", \"seul\", \"seule\", \"seulement\", \"si\", \"sien\", \"sienne\", \"siennes\", \"siens\",\n",
    " \"sinon\", \"six\", \"sixi√®me\", \"soi\", \"soi-m√™me\", \"soient\", \"sois\", \"soit\", \"soixante\", \"sommes\", \"son\", \"sont\", \"sous\",\n",
    " \"souvent\", \"soyez\", \"soyons\", \"specifique\", \"specifiques\", \"speculatif\", \"stop\", \"strictement\", \"subtiles\",\n",
    " \"suffisant\", \"suffisante\", \"suffit\", \"suis\", \"suit\", \"suivant\", \"suivante\", \"suivantes\", \"suivants\", \"suivre\", \"sujet\",\n",
    " \"superpose\", \"sur\", \"surtout\", \"t\", \"ta\", \"tac\", \"tandis\", \"tant\", \"tardive\", \"te\", \"tel\", \"telle\", \"tellement\",\n",
    " \"telles\", \"tels\", \"tenant\", \"tend\", \"tenir\", \"tente\", \"tes\", \"tic\", \"tien\", \"tienne\", \"tiennes\", \"tiens\", \"toc\", \"toi\",\n",
    " \"toi-m√™me\", \"ton\", \"touchant\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"tres\",\n",
    " \"trois\", \"troisi√®me\", \"troisi√®mement\", \"trop\", \"tr√®s\", \"tsoin\", \"tsouin\", \"tu\", \"t√©\", \"u\", \"un\", \"une\", \"unes\",\n",
    " \"uniformement\", \"unique\", \"uniques\", \"uns\", \"v\", \"va\", \"vais\", \"valeur\", \"vas\", \"vers\", \"via\", \"vif\", \"vifs\", \"vingt\",\n",
    " \"vivat\", \"vive\", \"vives\", \"vlan\", \"voici\", \"voie\", \"voient\", \"voil√†\", \"voire\", \"vont\", \"vos\", \"votre\", \"vous\",\n",
    " \"vous-m√™mes\", \"vu\", \"v√©\", \"v√¥tre\", \"v√¥tres\", \"w\", \"x\", \"y\", \"z\", \"zut\", \"√†\", \"√¢\", \"√ßa\", \"√®s\", \"√©taient\", \"√©tais\",\n",
    " \"√©tait\", \"√©tant\", \"√©tat\", \"√©tiez\", \"√©tions\", \"√©t√©\", \"√©t√©e\", \"√©t√©es\", \"√©t√©s\", \"√™tes\", \"√™tre\", \"√¥\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arabic-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_tweets_dataframe as cld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinguished-denver",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'clean_tweets_dataframe' from 'C:\\\\Users\\\\Faith Bagire\\\\PycharmProjects\\\\pythonProject\\\\tweets_analyze\\\\clean_tweets_dataframe.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(cld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=pd.read_excel(\"week2_new.xlsx\",engine='openpyxl',dtype={'tweet_id':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Action...!!!\n"
     ]
    }
   ],
   "source": [
    "cleaner=cld.CleanTweets(df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-fantasy",
   "metadata": {},
   "source": [
    "**Using cleaner module from clean_tweets_dataframe to clean the imported dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supported-clarity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16635, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extended-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.drop_unwanted_column(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collect-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.convert_to_datetime(df_tweet)\n",
    "df_tweet=cleaner.convert_to_numbers(df_tweet)\n",
    "df_tweet=cleaner.treat_special_characters(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "above-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.remove_other_languages_tweets(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "connected-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.drop_retweets(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seven-boost",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8680, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lang</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>...</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-31 12:24:57+00:00</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...</td>\n",
       "      <td>üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>2493</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Airdrop, Airdrops, Crypto</td>\n",
       "      <td>CryptoTownEU</td>\n",
       "      <td>dacca, bangladesh</td>\n",
       "      <td>https://twitter.com/Tusar03738675/status/15537...</td>\n",
       "      <td>1553718354913140736</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-31 12:23:57+00:00</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...</td>\n",
       "      <td>üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>1592</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Airdrop, Airdrops, Crypto</td>\n",
       "      <td>CryptoTownEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/FaiqMadani/status/15537181...</td>\n",
       "      <td>1553718105834389510</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-31 12:23:55+00:00</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>-The Best Opportunity To Earn Crypto Via Readi...</td>\n",
       "      <td>-The Best Opportunity To Earn Crypto Via Readi...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>286</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/RAjusiagram/status/1553718...</td>\n",
       "      <td>1553718097760071681</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-31 12:23:17+00:00</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>-The Best Opportunity To Earn Crypto Via Readi...</td>\n",
       "      <td>-The Best Opportunity To Earn Crypto Via Readi...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>2213</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/pacarnyaanya69/status/1553...</td>\n",
       "      <td>1553717936384544769</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-07-31 12:23:14+00:00</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...</td>\n",
       "      <td>üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Airdrop, Airdrops, Crypto</td>\n",
       "      <td>CryptoTownEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/DariushHaji11/status/15537...</td>\n",
       "      <td>1553717922316668928</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16591</th>\n",
       "      <td>2022-07-24 13:26:15+00:00</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @RwandaMoD: Today, Benin Armed Forces Chief...</td>\n",
       "      <td>Today, Benin Armed Forces Chief of Army Staff,...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>88</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RwandaMoD</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>https://twitter.com/Eva_Official___/status/155...</td>\n",
       "      <td>1551197068177412096</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16603</th>\n",
       "      <td>2022-07-24 13:02:14+00:00</td>\n",
       "      <td>EUwatch</td>\n",
       "      <td>Macron says Iran nuclear deal remains possible...</td>\n",
       "      <td>Macron says Iran nuclear deal remains possible...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25713</td>\n",
       "      <td>7631</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brussels</td>\n",
       "      <td>https://twitter.com/EUwatchers/status/15511910...</td>\n",
       "      <td>1551191023208079361</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16619</th>\n",
       "      <td>2022-07-24 12:41:55+00:00</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>RT @EUwatchers: Russia-Ukraine updates: Russia...</td>\n",
       "      <td>Russia-Ukraine updates: Russia says it hit mil...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1752</td>\n",
       "      <td>4352</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUwatchers</td>\n",
       "      <td>canada</td>\n",
       "      <td>https://twitter.com/mig30m6/status/15511859098...</td>\n",
       "      <td>1551185909802061824</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16629</th>\n",
       "      <td>2022-07-24 12:31:56+00:00</td>\n",
       "      <td>EUwatch</td>\n",
       "      <td>Macron says Iran nuclear deal 'still possible'...</td>\n",
       "      <td>Macron says Iran nuclear deal 'still possible'...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25713</td>\n",
       "      <td>7631</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brussels</td>\n",
       "      <td>https://twitter.com/EUwatchers/status/15511833...</td>\n",
       "      <td>1551183398491852801</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16632</th>\n",
       "      <td>2022-07-24 12:30:53+00:00</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>\"Macron says Iran nuclear deal remains possibl...</td>\n",
       "      <td>\"Macron says Iran nuclear deal remains possibl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>munich - pinakothek der modern</td>\n",
       "      <td>https://twitter.com/humanrobotcoll2/status/155...</td>\n",
       "      <td>1551183133034283009</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8680 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at               source  \\\n",
       "0     2022-07-31 12:24:57+00:00  Twitter for Android   \n",
       "2     2022-07-31 12:23:57+00:00      Twitter Web App   \n",
       "3     2022-07-31 12:23:55+00:00   Twitter for iPhone   \n",
       "4     2022-07-31 12:23:17+00:00  Twitter for Android   \n",
       "5     2022-07-31 12:23:14+00:00      Twitter Web App   \n",
       "...                         ...                  ...   \n",
       "16591 2022-07-24 13:26:15+00:00  Twitter for Android   \n",
       "16603 2022-07-24 13:02:14+00:00              EUwatch   \n",
       "16619 2022-07-24 12:41:55+00:00      Twitter Web App   \n",
       "16629 2022-07-24 12:31:56+00:00              EUwatch   \n",
       "16632 2022-07-24 12:30:53+00:00              Twitter   \n",
       "\n",
       "                                           original_text  \\\n",
       "0      RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...   \n",
       "2      RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...   \n",
       "3      -The Best Opportunity To Earn Crypto Via Readi...   \n",
       "4      -The Best Opportunity To Earn Crypto Via Readi...   \n",
       "5      RT @CryptoTownEU: üöÄ Airdrop: ReadFi\\nüí∞ Value: ...   \n",
       "...                                                  ...   \n",
       "16591  RT @RwandaMoD: Today, Benin Armed Forces Chief...   \n",
       "16603  Macron says Iran nuclear deal remains possible...   \n",
       "16619  RT @EUwatchers: Russia-Ukraine updates: Russia...   \n",
       "16629  Macron says Iran nuclear deal 'still possible'...   \n",
       "16632  \"Macron says Iran nuclear deal remains possibl...   \n",
       "\n",
       "                                            cleaned_text  polarity  \\\n",
       "0      üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...  0.000000   \n",
       "2      üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...  0.000000   \n",
       "3      -The Best Opportunity To Earn Crypto Via Readi...  0.683333   \n",
       "4      -The Best Opportunity To Earn Crypto Via Readi...  0.683333   \n",
       "5      üöÄ Airdrop: ReadFi\\nüí∞ Value: 20 $RDF ($1.2)\\nüë• ...  0.000000   \n",
       "...                                                  ...       ...   \n",
       "16591  Today, Benin Armed Forces Chief of Army Staff,...  0.050000   \n",
       "16603  Macron says Iran nuclear deal remains possible...  0.000000   \n",
       "16619  Russia-Ukraine updates: Russia says it hit mil... -0.100000   \n",
       "16629  Macron says Iran nuclear deal 'still possible'...  0.000000   \n",
       "16632  \"Macron says Iran nuclear deal remains possibl...  0.000000   \n",
       "\n",
       "       subjectivity sentiment lang  likes_count  reply_count  ...  \\\n",
       "0              0.00   Neutral   en            0            0  ...   \n",
       "2              0.00   Neutral   en            0            0  ...   \n",
       "3              0.45  Positive   en            0            0  ...   \n",
       "4              0.45  Positive   en            0            0  ...   \n",
       "5              0.00   Neutral   en            0            0  ...   \n",
       "...             ...       ...  ...          ...          ...  ...   \n",
       "16591          0.50  Positive   en            0            0  ...   \n",
       "16603          1.00   Neutral   en            0            0  ...   \n",
       "16619          0.10  Negative   en            0            0  ...   \n",
       "16629          1.00   Neutral   en            0            0  ...   \n",
       "16632          1.00   Neutral   en            0            0  ...   \n",
       "\n",
       "       followers_count friends_count  possibly_sensitive  hashtags  \\\n",
       "0                  252          2493               False       NaN   \n",
       "2                  124          1592               False       NaN   \n",
       "3                    6           286               False       NaN   \n",
       "4                   88          2213               False       NaN   \n",
       "5                    2            40               False       NaN   \n",
       "...                ...           ...                 ...       ...   \n",
       "16591              144            88               False       NaN   \n",
       "16603            25713          7631               False       NaN   \n",
       "16619             1752          4352               False       NaN   \n",
       "16629            25713          7631               False       NaN   \n",
       "16632               29             0               False       NaN   \n",
       "\n",
       "                retweet_hashtags user_mentions  \\\n",
       "0      Airdrop, Airdrops, Crypto  CryptoTownEU   \n",
       "2      Airdrop, Airdrops, Crypto  CryptoTownEU   \n",
       "3                            NaN           NaN   \n",
       "4                            NaN           NaN   \n",
       "5      Airdrop, Airdrops, Crypto  CryptoTownEU   \n",
       "...                          ...           ...   \n",
       "16591                        NaN     RwandaMoD   \n",
       "16603                        NaN           NaN   \n",
       "16619                        NaN    EUwatchers   \n",
       "16629                        NaN           NaN   \n",
       "16632                        NaN           NaN   \n",
       "\n",
       "                                place  \\\n",
       "0                   dacca, bangladesh   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "5                                 NaN   \n",
       "...                               ...   \n",
       "16591                          Rwanda   \n",
       "16603                        brussels   \n",
       "16619                          canada   \n",
       "16629                        brussels   \n",
       "16632  munich - pinakothek der modern   \n",
       "\n",
       "                                               tweet_url             tweet_id  \\\n",
       "0      https://twitter.com/Tusar03738675/status/15537...  1553718354913140736   \n",
       "2      https://twitter.com/FaiqMadani/status/15537181...  1553718105834389510   \n",
       "3      https://twitter.com/RAjusiagram/status/1553718...  1553718097760071681   \n",
       "4      https://twitter.com/pacarnyaanya69/status/1553...  1553717936384544769   \n",
       "5      https://twitter.com/DariushHaji11/status/15537...  1553717922316668928   \n",
       "...                                                  ...                  ...   \n",
       "16591  https://twitter.com/Eva_Official___/status/155...  1551197068177412096   \n",
       "16603  https://twitter.com/EUwatchers/status/15511910...  1551191023208079361   \n",
       "16619  https://twitter.com/mig30m6/status/15511859098...  1551185909802061824   \n",
       "16629  https://twitter.com/EUwatchers/status/15511833...  1551183398491852801   \n",
       "16632  https://twitter.com/humanrobotcoll2/status/155...  1551183133034283009   \n",
       "\n",
       "      tweet_category  \n",
       "0            Retweet  \n",
       "2            Retweet  \n",
       "3              Tweet  \n",
       "4              Tweet  \n",
       "5            Retweet  \n",
       "...              ...  \n",
       "16591        Retweet  \n",
       "16603          Tweet  \n",
       "16619        Retweet  \n",
       "16629          Tweet  \n",
       "16632          Tweet  \n",
       "\n",
       "[8680 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_tweet.shape)\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "applied-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = df_tweet[df_tweet.original_author != 'dwnews']\n",
    "df_tweet = df_tweet[df_tweet.original_author != '123_INFO_DE']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'rogue_corq']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'Noticieros_MEX']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'EUwatchers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "federal-portable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en      7788\n",
       "fr       409\n",
       "kiny      60\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pending-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweet.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-colombia",
   "metadata": {},
   "source": [
    "###  Export french tweets, make translation and insert back new translated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hispanic-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans=df_tweet.query(\"lang=='fr'| lang =='kiny'\")[['original_text','cleaned_text','lang']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-february",
   "metadata": {},
   "source": [
    "### Translation with Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "noticed-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "charitable-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = pygsheets.authorize(service_file='tweet-auto-01-833e318c05c8.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fatty-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = gc.open('make_trans')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "breeding-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.set_dataframe(df_trans,start='A1',copy_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "victorian-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet.update_value('E1','translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mounted-humanity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.google.com/spreadsheets/d/1ITYeneA29Vvk_wKESJh5J92reOKcyjDQNo_yitMXPGc/edit#gid=0\n"
     ]
    }
   ],
   "source": [
    "# Browse the doc and make translations manually\n",
    "print(sheet.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2,len(df_trans)+2):\n",
    "#     sheet.update_value('E'+str(i),'=GOOGLETRANSLATE(C'+str(i)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_translate=df_tweet.query(\"lang=='fr'| lang =='kiny'\")['cleaned_text'].to_dict()\n",
    "dict_translated=sheet.get_as_df(index_column=1)[['translation']].to_dict()['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_to_translate.keys():\n",
    "    df_tweet.loc[idx, 'cleaned_text'] = dict_translated[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_translated.keys():\n",
    "    blob = TextBlob(clean(dict_translated[idx], no_emoji=True))\n",
    "    pol = blob.sentiment.polarity\n",
    "    df_tweet.loc[idx, 'sentiment'] = 'Positive' if pol > 0 else (\n",
    "        'Negative' if pol < 0 else 'Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-reset",
   "metadata": {},
   "source": [
    "#### Save new dataframe for dashboard creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet['created_at'] = df_tweet['created_at'].apply(lambda x: x.replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_excel('plotly_dashboard/processed_tweet_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-sharp",
   "metadata": {},
   "source": [
    "**Now we continue with Tweet and Replies Only! Excluding Retweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=df_tweet.query(\"tweet_category=='Tweet' or tweet_category== 'Reply'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-foundation",
   "metadata": {},
   "source": [
    "### EDA of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in every column\n",
    "ax = df_tweet.isna().sum().sort_values().plot(kind = 'barh', figsize = (7, 9))\n",
    "plt.title('Percentage of Missing Values Per Column in Tweets data', fontdict={'size':15})\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.3f}%'.format((p.get_width()/df_tweet.shape[0])*100)\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-knight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweet['place'].value_counts(sort=True, ascending=False)[:10].plot(kind='barh',\n",
    "                                                                     figsize=(12,5),xlabel='Place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date=df_tweet.set_index('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date.resample('D').mean()[['polarity','subjectivity']].dropna().plot(figsize=(10,6),xlabel='Date,time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-grenada",
   "metadata": {},
   "source": [
    "### uni-variate Analysis on Hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df=df_tweet[['original_text','hashtags','retweet_hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(df_tweet):\n",
    "    '''This function will extract hashtags'''\n",
    "    return re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', df_tweet)\n",
    "\n",
    "hashtag_df['hashtag_check']=df_tweet.original_text.apply(find_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df.dropna(subset=['hashtag_check'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list=list(hashtag_df['hashtag_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df = pd.DataFrame([tag for tags_row in tags_list for tag in tags_row],columns=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Actual Hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert hastags to lowercase\n",
    "hashtags_list_df['hashtag'] = hashtags_list_df['hashtag'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Hashtags in Lowercase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary=df_tweet.groupby('original_author').agg({'cleaned_text':'count','followers_count':'max',\n",
    "                                         'polarity':'mean','subjectivity':'mean', 'sentiment':pd.Series.mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary.sort_values(by='cleaned_text',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-bridal",
   "metadata": {},
   "source": [
    "Sentiment summary of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped = df_tweet.groupby('sentiment').count()['cleaned_text'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-blair",
   "metadata": {},
   "source": [
    "**Most frequent words in our tweets dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets=df_tweet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text Preprocessing\n",
    "english_tweets['cleaned_text'] = english_tweets['cleaned_text'].apply(\n",
    "    lambda x: clean(x,\n",
    "                    no_emoji=True,\n",
    "                    lower=True,\n",
    "                    no_punct=True,\n",
    "                    no_line_breaks=True,\n",
    "                    no_currency_symbols=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=' '.join(english_tweets.cleaned_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_obj=WordCloud(width=1000,height=600,stopwords=STOPWORDS).generate(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-background",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "fgg=plt.imshow(wordcloud_obj)\n",
    "plt.axis('off')\n",
    "# plt.title('Most Frequent Words In Our Tweets',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgg.figure.savefig('plotly_dashboard/cw_rdf.png',bbox_inches='tight',pad_inches=0)\n",
    "# fgg.figure.savefig('plotly_dashboard/assets/cw_rdf.png',bbox_inches='tight',pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-macro",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tweets_df):\n",
    "    # Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['cleaned_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "    #Save only words and excludes emojis, punctuations\n",
    "    word_list_new=[]\n",
    "    for sent in word_list:\n",
    "        word_list_new.append([re.split(r'\\W+',word) for word in sent if word not in STOPWORDS and not word.isdigit()])\n",
    "    \n",
    "    word_list_final=[]\n",
    "    for sent in word_list_new:\n",
    "        word_list_final.append([i[0] for i in sent])\n",
    "    # Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list_final)\n",
    "    corpus_1 = [word_to_id.doc2bow(tweet) for tweet in word_list_final]\n",
    "\n",
    "    return word_list_final, word_to_id, corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, id2word, corpus=preprocess_data(english_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-greensboro",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-niger",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-diamond",
   "metadata": {},
   "source": [
    "**Model 1 words with some digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.857909007134007\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4242327533406264\n",
    "\n",
    "**Model 2 words without digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.82031321033761\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4368570452021986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-cutting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-humor",
   "metadata": {},
   "source": [
    "###  END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-popularity",
   "metadata": {},
   "source": [
    "**Number of Topics optimatization**\n",
    "\n",
    "As we can see the coherence accuracy increases with number of topics which is expected but again \\\n",
    "many topics again would lead to meaningless conclusion. Let's use elbow method to find optimum number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best LDA Model considering different number of topics\n",
    "\n",
    "# params_dic={'topics_number':[],'coherence':[],'perplexity':[]}\n",
    "# for top_number in range(1,10):\n",
    "#     lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                             id2word=id2word,\n",
    "#                                             num_topics=top_number, \n",
    "#                                             random_state=100,\n",
    "#                                             update_every=1,\n",
    "#                                             chunksize=100,\n",
    "#                                             passes=10,\n",
    "#                                             alpha='auto',\n",
    "#                                             per_word_topics=False)\n",
    "    \n",
    "#     perplexity=lda_model.log_perplexity(corpus)  \n",
    "#     # Compute Coherence Score\n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "#     coherence_lda = coherence_model_lda.get_coherence()\n",
    "#     params_dic['topics_number'].append(top_number)\n",
    "#     params_dic['coherence'].append(coherence_lda)\n",
    "#     params_dic['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-auckland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(params_dic).plot(y=['coherence'])\n",
    "# # pd.read_csv(\"elbow_metrics.csv\",index_col=0).plot(y=['coherence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = list(np.arange(0.01, 3, 0.1))\n",
    "# alphas.append('symmetric')\n",
    "# alphas.append('asymmetric')\n",
    "# alphas.append('auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best LDA Model considering different number of alpha\n",
    "\n",
    "# params_dic_alpha={'alpha':[],'coherence':[],'perplexity':[]}\n",
    "# for alpha in alphas:\n",
    "#     lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                             id2word=id2word,\n",
    "#                                             num_topics=7, \n",
    "#                                             random_state=100,\n",
    "#                                             update_every=1,\n",
    "#                                             chunksize=100,\n",
    "#                                             passes=10,\n",
    "#                                             alpha=alpha,\n",
    "#                                             per_word_topics=False)\n",
    "    \n",
    "#     perplexity=lda_model.log_perplexity(corpus)  \n",
    "#     # Compute Coherence Score\n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "#     coherence_lda = coherence_model_lda.get_coherence()\n",
    "#     params_dic_alpha['alpha'].append(alpha)\n",
    "#     params_dic_alpha['coherence'].append(coherence_lda)\n",
    "#     params_dic_alpha['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(params_dic_alpha).plot(y='coherence')#.sort_values('coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-territory",
   "metadata": {},
   "source": [
    "**Model with selected optimum parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=7, \n",
    "#                                            random_state=100,\n",
    "#                                            update_every=1,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            alpha=0.1,\n",
    "#                                            per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Perplexity\n",
    "# #It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# # doc_lda = lda_model[corpus]\n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "# LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
