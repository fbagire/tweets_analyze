{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "different-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "from importlib import reload\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import string\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documented-violence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS.update([\"a\",\"will\",\"el\",\"del\",\"lo\", \"abord\", \"absolument\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ailleurs\", \"ainsi\", \"ait\", \"allaient\", \"allo\",\n",
    " \"allons\", \"allô\", \"alors\", \"anterieur\", \"anterieure\", \"anterieures\", \"apres\", \"après\", \"as\", \"assez\", \"attendu\", \"au\",\n",
    " \"aucun\", \"aucune\", \"aucuns\", \"aujourd\", \"aujourd'hui\", \"aupres\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\",\n",
    " \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autant\", \"autre\", \"autrefois\",\n",
    " \"autrement\", \"autres\", \"autrui\", \"aux\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\",\n",
    " \"aviez\", \"avions\", \"avoir\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"bas\", \"basee\", \"bat\", \"beau\", \"beaucoup\",\n",
    " \"bien\", \"bigre\", \"bon\", \"boum\", \"bravo\", \"brrr\", \"c\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-là\",\n",
    " \"celles\", \"celles-ci\", \"celles-là\", \"celui\", \"celui-ci\", \"celui-là\", \"celà\", \"cent\", \"cependant\", \"certain\",\n",
    " \"certaine\", \"certaines\", \"certains\", \"certes\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-là\", \"chacun\",\n",
    " \"chacune\", \"chaque\", \"cher\", \"chers\", \"chez\", \"chiche\", \"chut\", \"chère\", \"chères\", \"ci\", \"cinq\", \"cinquantaine\",\n",
    " \"cinquante\", \"cinquantième\", \"cinquième\", \"clac\", \"clic\", \"combien\", \"comme\", \"comment\", \"comparable\", \"comparables\",\n",
    " \"compris\", \"concernant\", \"contre\", \"couic\", \"crac\", \"d\", \"da\", \"dans\", \"de\", \"debout\", \"dedans\", \"dehors\", \"deja\",\n",
    " \"delà\", \"depuis\", \"dernier\", \"derniere\", \"derriere\", \"derrière\", \"des\", \"desormais\", \"desquelles\", \"desquels\",\n",
    " \"dessous\", \"dessus\", \"deux\", \"deuxième\", \"deuxièmement\", \"devant\", \"devers\", \"devra\", \"devrait\", \"different\",\n",
    " \"differentes\", \"differents\", \"différent\", \"différente\", \"différentes\", \"différents\", \"dire\", \"directe\", \"directement\",\n",
    " \"dit\", \"dite\", \"dits\", \"divers\", \"diverse\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dixième\", \"doit\",\n",
    " \"doivent\", \"donc\", \"dont\", \"dos\", \"douze\", \"douzième\", \"dring\", \"droite\", \"du\", \"duquel\", \"durant\", \"dès\", \"début\",\n",
    " \"désormais\", \"e\", \"effet\", \"egale\", \"egalement\", \"egales\", \"eh\", \"elle\", \"elle-même\", \"elles\", \"elles-mêmes\", \"en\",\n",
    " \"encore\", \"enfin\", \"entre\", \"envers\", \"environ\", \"es\", \"essai\", \"est\", \"et\", \"etant\", \"etc\", \"etre\", \"eu\", \"eue\",\n",
    " \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"eux-mêmes\",\n",
    " \"exactement\", \"excepté\", \"extenso\", \"exterieur\", \"eûmes\", \"eût\", \"eûtes\", \"f\", \"fais\", \"faisaient\", \"faisant\", \"fait\",\n",
    " \"faites\", \"façon\", \"feront\", \"fi\", \"flac\", \"floc\", \"fois\", \"font\", \"force\", \"furent\", \"fus\", \"fusse\", \"fussent\",\n",
    " \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"fûmes\", \"fût\", \"fûtes\", \"g\", \"gens\", \"h\", \"ha\", \"haut\", \"hein\", \"hem\", \"hep\",\n",
    " \"hi\", \"ho\", \"holà\", \"hop\", \"hormis\", \"hors\", \"hou\", \"houp\", \"hue\", \"hui\", \"huit\", \"huitième\", \"hum\", \"hurrah\", \"hé\",\n",
    " \"hélas\", \"i\", \"ici\", \"il\", \"ils\", \"importe\", \"j\", \"je\", \"jusqu\", \"jusque\", \"juste\", \"k\", \"l\", \"la\", \"laisser\",\n",
    " \"laquelle\", \"las\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"longtemps\", \"lors\", \"lorsque\",\n",
    " \"lui\", \"lui-meme\", \"lui-même\", \"là\", \"lès\", \"m\", \"ma\", \"maint\", \"maintenant\", \"mais\", \"malgre\", \"malgré\", \"maximale\",\n",
    " \"me\", \"meme\", \"memes\", \"merci\", \"mes\", \"mien\", \"mienne\", \"miennes\", \"miens\", \"mille\", \"mince\", \"mine\", \"minimale\",\n",
    " \"moi\", \"moi-meme\", \"moi-même\", \"moindres\", \"moins\", \"mon\", \"mot\", \"moyennant\", \"multiple\", \"multiples\", \"même\",\n",
    " \"mêmes\", \"n\", \"na\", \"naturel\", \"naturelle\", \"naturelles\", \"ne\", \"neanmoins\", \"necessaire\", \"necessairement\", \"neuf\",\n",
    " \"neuvième\", \"ni\", \"nombreuses\", \"nombreux\", \"nommés\", \"non\", \"nos\", \"notamment\", \"notre\", \"nous\", \"nous-mêmes\",\n",
    " \"nouveau\", \"nouveaux\", \"nul\", \"néanmoins\", \"nôtre\", \"nôtres\", \"o\", \"oh\", \"ohé\", \"ollé\", \"olé\", \"on\", \"ont\", \"onze\",\n",
    " \"onzième\", \"ore\", \"ou\", \"ouf\", \"ouias\", \"oust\", \"ouste\", \"outre\", \"ouvert\", \"ouverte\", \"ouverts\", \"o|\", \"où\", \"p\",\n",
    " \"paf\", \"pan\", \"par\", \"parce\", \"parfois\", \"parle\", \"parlent\", \"parler\", \"parmi\", \"parole\", \"parseme\", \"partant\",\n",
    " \"particulier\", \"particulière\", \"particulièrement\", \"pas\", \"passé\", \"pendant\", \"pense\", \"permet\", \"personne\",\n",
    " \"personnes\", \"peu\", \"peut\", \"peuvent\", \"peux\", \"pff\", \"pfft\", \"pfut\", \"pif\", \"pire\", \"pièce\", \"plein\", \"plouf\",\n",
    " \"plupart\", \"plus\", \"plusieurs\", \"plutôt\", \"possessif\", \"possessifs\", \"possible\", \"possibles\", \"pouah\", \"pour\",\n",
    " \"pourquoi\", \"pourrais\", \"pourrait\", \"pouvait\", \"prealable\", \"precisement\", \"premier\", \"première\", \"premièrement\",\n",
    " \"pres\", \"probable\", \"probante\", \"procedant\", \"proche\", \"près\", \"psitt\", \"pu\", \"puis\", \"puisque\", \"pur\", \"pure\", \"q\",\n",
    " \"qu\", \"quand\", \"quant\", \"quant-à-soi\", \"quanta\", \"quarante\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatrième\",\n",
    " \"quatrièmement\", \"que\", \"quel\", \"quelconque\", \"quelle\", \"quelles\", \"quelqu'un\", \"quelque\", \"quelques\", \"quels\", \"qui\",\n",
    " \"quiconque\", \"quinze\", \"quoi\", \"quoique\", \"r\", \"rare\", \"rarement\", \"rares\", \"relative\", \"relativement\", \"remarquable\",\n",
    " \"rend\", \"rendre\", \"restant\", \"reste\", \"restent\", \"restrictif\", \"retour\", \"revoici\", \"revoilà\", \"rien\", \"s\", \"sa\",\n",
    " \"sacrebleu\", \"sait\", \"sans\", \"sapristi\", \"sauf\", \"se\", \"sein\", \"seize\", \"selon\", \"semblable\", \"semblaient\", \"semble\",\n",
    " \"semblent\", \"sent\", \"sept\", \"septième\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\",\n",
    " \"serions\", \"serons\", \"seront\", \"ses\", \"seul\", \"seule\", \"seulement\", \"si\", \"sien\", \"sienne\", \"siennes\", \"siens\",\n",
    " \"sinon\", \"six\", \"sixième\", \"soi\", \"soi-même\", \"soient\", \"sois\", \"soit\", \"soixante\", \"sommes\", \"son\", \"sont\", \"sous\",\n",
    " \"souvent\", \"soyez\", \"soyons\", \"specifique\", \"specifiques\", \"speculatif\", \"stop\", \"strictement\", \"subtiles\",\n",
    " \"suffisant\", \"suffisante\", \"suffit\", \"suis\", \"suit\", \"suivant\", \"suivante\", \"suivantes\", \"suivants\", \"suivre\", \"sujet\",\n",
    " \"superpose\", \"sur\", \"surtout\", \"t\", \"ta\", \"tac\", \"tandis\", \"tant\", \"tardive\", \"te\", \"tel\", \"telle\", \"tellement\",\n",
    " \"telles\", \"tels\", \"tenant\", \"tend\", \"tenir\", \"tente\", \"tes\", \"tic\", \"tien\", \"tienne\", \"tiennes\", \"tiens\", \"toc\", \"toi\",\n",
    " \"toi-même\", \"ton\", \"touchant\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"tres\",\n",
    " \"trois\", \"troisième\", \"troisièmement\", \"trop\", \"très\", \"tsoin\", \"tsouin\", \"tu\", \"té\", \"u\", \"un\", \"une\", \"unes\",\n",
    " \"uniformement\", \"unique\", \"uniques\", \"uns\", \"v\", \"va\", \"vais\", \"valeur\", \"vas\", \"vers\", \"via\", \"vif\", \"vifs\", \"vingt\",\n",
    " \"vivat\", \"vive\", \"vives\", \"vlan\", \"voici\", \"voie\", \"voient\", \"voilà\", \"voire\", \"vont\", \"vos\", \"votre\", \"vous\",\n",
    " \"vous-mêmes\", \"vu\", \"vé\", \"vôtre\", \"vôtres\", \"w\", \"x\", \"y\", \"z\", \"zut\", \"à\", \"â\", \"ça\", \"ès\", \"étaient\", \"étais\",\n",
    " \"était\", \"étant\", \"état\", \"étiez\", \"étions\", \"été\", \"étée\", \"étées\", \"étés\", \"êtes\", \"être\", \"ô\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arabic-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_tweets_dataframe as cld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinguished-denver",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'clean_tweets_dataframe' from 'C:\\\\Users\\\\Faith Bagire\\\\PycharmProjects\\\\pythonProject\\\\tweets_analyze\\\\clean_tweets_dataframe.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(cld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=pd.read_excel(\"processed_tweet_data.xlsx\",engine='openpyxl',dtype={'tweet_id':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Action...!!!\n"
     ]
    }
   ],
   "source": [
    "cleaner=cld.CleanTweets(df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-fantasy",
   "metadata": {},
   "source": [
    "**Using cleaner module from clean_tweets_dataframe to clean the imported dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supported-clarity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10423, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extended-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.drop_unwanted_column(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collect-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.convert_to_datetime(df_tweet)\n",
    "df_tweet=cleaner.convert_to_numbers(df_tweet)\n",
    "df_tweet=cleaner.treat_special_characters(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "above-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.remove_other_languages_tweets(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "connected-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.drop_retweets(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seven-boost",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3833, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lang</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>...</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-07-18 15:25:28+00:00</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @TheoMpoze: ‘It shouldn’t be happening agai...</td>\n",
       "      <td>‘It shouldn’t be happening again’:  rebels ret...</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1579</td>\n",
       "      <td>418</td>\n",
       "      <td>False</td>\n",
       "      <td>M23, DRC</td>\n",
       "      <td>M23, DRC, Kivu, RDF, Kagame</td>\n",
       "      <td>TheoMpoze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Nduwamungu5/status/1549052...</td>\n",
       "      <td>1549052740772429826</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-07-18 15:21:48+00:00</td>\n",
       "      <td>EUwatch</td>\n",
       "      <td>European heat wave: Britain announces national...</td>\n",
       "      <td>European heat wave: Britain announces national...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25730</td>\n",
       "      <td>7621</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brussels</td>\n",
       "      <td>https://twitter.com/EUwatchers/status/15490518...</td>\n",
       "      <td>1549051820839825408</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-07-18 15:19:37+00:00</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @EUwatchers: European heat wave: Britain an...</td>\n",
       "      <td>European heat wave: Britain announces national...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3903</td>\n",
       "      <td>4278</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUwatchers</td>\n",
       "      <td>groland</td>\n",
       "      <td>https://twitter.com/Zgur_/status/1549051269184...</td>\n",
       "      <td>1549051269184372736</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-07-18 15:14:41+00:00</td>\n",
       "      <td>Microsoft Power Platform</td>\n",
       "      <td>Why are weather forecasts not always accurate?...</td>\n",
       "      <td>Why are weather forecasts not always accurate?...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>123INFO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>germany</td>\n",
       "      <td>https://twitter.com/123_INFO_DE/status/1549050...</td>\n",
       "      <td>1549050029469364225</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-07-18 15:10:04+00:00</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @aqlila1: Tried to draw Rovina Desamero of ...</td>\n",
       "      <td>Tried to draw Rovina Desamero of Dosage of Ser...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>621</td>\n",
       "      <td>1559</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aqlila1, inksteadywp</td>\n",
       "      <td>farm ni doh kyung soo</td>\n",
       "      <td>https://twitter.com/AriaSoondingie/status/1549...</td>\n",
       "      <td>1549048865307111424</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10412</th>\n",
       "      <td>2022-07-11 15:53:52+00:00</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>Thank you everyone who joined us for our RDF A...</td>\n",
       "      <td>Thank you everyone who joined us for our RDF A...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2452</td>\n",
       "      <td>340</td>\n",
       "      <td>False</td>\n",
       "      <td>UnidosUS22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phoenix, az</td>\n",
       "      <td>https://twitter.com/RazaFund/status/1546523173...</td>\n",
       "      <td>1546523173314772994</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10414</th>\n",
       "      <td>2022-07-11 15:51:46+00:00</td>\n",
       "      <td>EUwatch</td>\n",
       "      <td>Srebrenica massacre: Netherlands apologizes af...</td>\n",
       "      <td>Srebrenica massacre: Netherlands apologizes af...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25730</td>\n",
       "      <td>7621</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brussels</td>\n",
       "      <td>https://twitter.com/EUwatchers/status/15465226...</td>\n",
       "      <td>1546522645314904069</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>2022-07-11 15:51:32+00:00</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Rwanda Security forces, (RDF &amp;amp; RNP)  70-80...</td>\n",
       "      <td>Rwanda Security forces, (RDF &amp;amp; RNP)  70-80...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1580</td>\n",
       "      <td>1591</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/MurindwaJames/status/15465...</td>\n",
       "      <td>1546522588502949888</td>\n",
       "      <td>Tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>2022-07-11 15:46:37+00:00</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @rbarwanda: JUST IN\\nPresident Kagame and C...</td>\n",
       "      <td>JUST IN\\nPresident Kagame and Commander-In-Chi...</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3792</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rbarwanda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/KayinamuraJose4/status/154...</td>\n",
       "      <td>1546521351791542273</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10421</th>\n",
       "      <td>2022-07-11 15:46:33+00:00</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @FactsOnRwanda: Several top military leader...</td>\n",
       "      <td>Several top military leaders in Rwanda Defense...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3792</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FactsOnRwanda, RwOT</td>\n",
       "      <td>FactsOnRwanda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/KayinamuraJose4/status/154...</td>\n",
       "      <td>1546521331851821057</td>\n",
       "      <td>Retweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3833 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at                    source  \\\n",
       "8     2022-07-18 15:25:28+00:00       Twitter for Android   \n",
       "9     2022-07-18 15:21:48+00:00                   EUwatch   \n",
       "12    2022-07-18 15:19:37+00:00       Twitter for Android   \n",
       "17    2022-07-18 15:14:41+00:00  Microsoft Power Platform   \n",
       "18    2022-07-18 15:10:04+00:00        Twitter for iPhone   \n",
       "...                         ...                       ...   \n",
       "10412 2022-07-11 15:53:52+00:00            Hootsuite Inc.   \n",
       "10414 2022-07-11 15:51:46+00:00                   EUwatch   \n",
       "10416 2022-07-11 15:51:32+00:00           Twitter Web App   \n",
       "10420 2022-07-11 15:46:37+00:00        Twitter for iPhone   \n",
       "10421 2022-07-11 15:46:33+00:00        Twitter for iPhone   \n",
       "\n",
       "                                           original_text  \\\n",
       "8      RT @TheoMpoze: ‘It shouldn’t be happening agai...   \n",
       "9      European heat wave: Britain announces national...   \n",
       "12     RT @EUwatchers: European heat wave: Britain an...   \n",
       "17     Why are weather forecasts not always accurate?...   \n",
       "18     RT @aqlila1: Tried to draw Rovina Desamero of ...   \n",
       "...                                                  ...   \n",
       "10412  Thank you everyone who joined us for our RDF A...   \n",
       "10414  Srebrenica massacre: Netherlands apologizes af...   \n",
       "10416  Rwanda Security forces, (RDF &amp; RNP)  70-80...   \n",
       "10420  RT @rbarwanda: JUST IN\\nPresident Kagame and C...   \n",
       "10421  RT @FactsOnRwanda: Several top military leader...   \n",
       "\n",
       "                                            cleaned_text  polarity  \\\n",
       "8      ‘It shouldn’t be happening again’:  rebels ret... -0.150000   \n",
       "9      European heat wave: Britain announces national...  0.000000   \n",
       "12     European heat wave: Britain announces national...  0.000000   \n",
       "17     Why are weather forecasts not always accurate?...  0.400000   \n",
       "18     Tried to draw Rovina Desamero of Dosage of Ser...  0.000000   \n",
       "...                                                  ...       ...   \n",
       "10412  Thank you everyone who joined us for our RDF A...  0.433333   \n",
       "10414  Srebrenica massacre: Netherlands apologizes af...  0.000000   \n",
       "10416  Rwanda Security forces, (RDF &amp; RNP)  70-80...  0.000000   \n",
       "10420  JUST IN\\nPresident Kagame and Commander-In-Chi...  0.037500   \n",
       "10421  Several top military leaders in Rwanda Defense... -0.083333   \n",
       "\n",
       "       subjectivity sentiment lang  likes_count  reply_count  ...  \\\n",
       "8          0.100000  Negative   en            0            0  ...   \n",
       "9          0.000000   Neutral   en            0            0  ...   \n",
       "12         0.000000   Neutral   en            0            0  ...   \n",
       "17         0.633333  Positive   en            0            0  ...   \n",
       "18         0.000000   Neutral   en            0            0  ...   \n",
       "...             ...       ...  ...          ...          ...  ...   \n",
       "10412      0.505556  Positive   en            6            0  ...   \n",
       "10414      0.000000   Neutral   en            0            0  ...   \n",
       "10416      0.000000   Neutral   en            4            0  ...   \n",
       "10420      0.366667  Positive   en            0            0  ...   \n",
       "10421      0.266667  Negative   en            0            0  ...   \n",
       "\n",
       "       followers_count friends_count  possibly_sensitive    hashtags  \\\n",
       "8                 1579           418               False    M23, DRC   \n",
       "9                25730          7621               False         NaN   \n",
       "12                3903          4278               False         NaN   \n",
       "17                 118            12               False     123INFO   \n",
       "18                 621          1559               False         NaN   \n",
       "...                ...           ...                 ...         ...   \n",
       "10412             2452           340               False  UnidosUS22   \n",
       "10414            25730          7621               False         NaN   \n",
       "10416             1580          1591               False         NaN   \n",
       "10420             3792          5000               False         NaN   \n",
       "10421             3792          5000               False         NaN   \n",
       "\n",
       "                  retweet_hashtags         user_mentions  \\\n",
       "8      M23, DRC, Kivu, RDF, Kagame             TheoMpoze   \n",
       "9                              NaN                   NaN   \n",
       "12                             NaN            EUwatchers   \n",
       "17                             NaN                   NaN   \n",
       "18                             NaN  aqlila1, inksteadywp   \n",
       "...                            ...                   ...   \n",
       "10412                          NaN                   NaN   \n",
       "10414                          NaN                   NaN   \n",
       "10416                          NaN                   NaN   \n",
       "10420                          NaN             rbarwanda   \n",
       "10421          FactsOnRwanda, RwOT         FactsOnRwanda   \n",
       "\n",
       "                        place  \\\n",
       "8                         NaN   \n",
       "9                    brussels   \n",
       "12                    groland   \n",
       "17                    germany   \n",
       "18      farm ni doh kyung soo   \n",
       "...                       ...   \n",
       "10412             phoenix, az   \n",
       "10414                brussels   \n",
       "10416                     NaN   \n",
       "10420                     NaN   \n",
       "10421                     NaN   \n",
       "\n",
       "                                               tweet_url             tweet_id  \\\n",
       "8      https://twitter.com/Nduwamungu5/status/1549052...  1549052740772429826   \n",
       "9      https://twitter.com/EUwatchers/status/15490518...  1549051820839825408   \n",
       "12     https://twitter.com/Zgur_/status/1549051269184...  1549051269184372736   \n",
       "17     https://twitter.com/123_INFO_DE/status/1549050...  1549050029469364225   \n",
       "18     https://twitter.com/AriaSoondingie/status/1549...  1549048865307111424   \n",
       "...                                                  ...                  ...   \n",
       "10412  https://twitter.com/RazaFund/status/1546523173...  1546523173314772994   \n",
       "10414  https://twitter.com/EUwatchers/status/15465226...  1546522645314904069   \n",
       "10416  https://twitter.com/MurindwaJames/status/15465...  1546522588502949888   \n",
       "10420  https://twitter.com/KayinamuraJose4/status/154...  1546521351791542273   \n",
       "10421  https://twitter.com/KayinamuraJose4/status/154...  1546521331851821057   \n",
       "\n",
       "      tweet_category  \n",
       "8            Retweet  \n",
       "9              Tweet  \n",
       "12           Retweet  \n",
       "17             Tweet  \n",
       "18           Retweet  \n",
       "...              ...  \n",
       "10412          Tweet  \n",
       "10414          Tweet  \n",
       "10416          Tweet  \n",
       "10420        Retweet  \n",
       "10421        Retweet  \n",
       "\n",
       "[3833 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_tweet.shape)\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "federal-portable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Retweet    2780\n",
       "Tweet       667\n",
       "Reply       386\n",
       "Name: tweet_category, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet['tweet_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pending-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweet.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-colombia",
   "metadata": {},
   "source": [
    "###  Export french tweets, make translation and insert back new translated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hispanic-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans=df_tweet.query(\"lang=='fr'| lang =='kiny'\")[['original_text','cleaned_text','lang']]\n",
    "df_trans.to_excel('df_to_translate.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-february",
   "metadata": {},
   "source": [
    "### translation completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_translate=df_tweet.query(\"lang=='fr'| lang =='kiny'\")['cleaned_text'].to_dict()\n",
    "\n",
    "dict_translated=pd.read_excel('df_translated.xlsx',engine='openpyxl',index_col=0,usecols=[0,4]).to_dict()['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_to_translate.keys():\n",
    "    df_tweet.loc[idx, 'cleaned_text'] = dict_translated[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet[['original_author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_translated.keys():\n",
    "    blob = TextBlob(dict_translated[idx])\n",
    "    pol=blob.sentiment.polarity\n",
    "    df_tweet.loc[idx, 'sentiment'] = 'Positive' if pol>0 else ('Negative' if pol < 0 else 'Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-reset",
   "metadata": {},
   "source": [
    "#### Save new dataframe for dashboard creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet['created_at'] = df_tweet['created_at'].apply(lambda x: x.replace(tzinfo=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweet.to_excel('plotly_dashboard/processed_tweet_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-cursor",
   "metadata": {},
   "source": [
    "**Now we continue with Tweet and Replies Only! Excluding Retweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=df_tweet.query(\"tweet_category=='Tweet' or tweet_category== 'Reply'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet = df_tweet[df_tweet.original_author != 'republikaonline']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'dwnews']\n",
    "df_tweet = df_tweet[df_tweet.original_author != '123_INFO_DE']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'rogue_corq']\n",
    "df_tweet = df_tweet[df_tweet.original_author != 'Noticieros_MEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-burns",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mostflwd=df_tweet[['original_author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mostflwd.dropna(inplace=True)\n",
    "d_mostflwd['hh']=d_mostflwd['original_author'].apply(lambda x : '['+x+']'+'(https://twitter.com/'+str(x)+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-foundation",
   "metadata": {},
   "source": [
    "### EDA of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in every column\n",
    "ax = df_tweet.isna().sum().sort_values().plot(kind = 'barh', figsize = (7, 9))\n",
    "plt.title('Percentage of Missing Values Per Column in Tweets data', fontdict={'size':15})\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.3f}%'.format((p.get_width()/df_tweet.shape[0])*100)\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-lesbian",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dict(df_tweet['place'].value_counts()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-knight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweet['place'].value_counts(sort=True, ascending=False)[:10].plot(kind='barh',\n",
    "                                                                     figsize=(12,5),xlabel='Place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date=df_tweet.set_index('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date.resample('D').mean()[['polarity','subjectivity']].dropna().plot(figsize=(10,6),xlabel='Date,time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-grenada",
   "metadata": {},
   "source": [
    "### uni-variate Analysis on Hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df=df_tweet[['original_text','hashtags','retweet_hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(df_tweet):\n",
    "    '''This function will extract hashtags'''\n",
    "    return re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', df_tweet)\n",
    "\n",
    "hashtag_df['hashtag_check']=df_tweet.original_text.apply(find_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df.dropna(subset=['hashtag_check'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list=list(hashtag_df['hashtag_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df = pd.DataFrame([tag for tags_row in tags_list for tag in tags_row],columns=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Actual Hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert hastags to lowercase\n",
    "hashtags_list_df['hashtag'] = hashtags_list_df['hashtag'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Hashtags in Lowercase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary=df_tweet.groupby('original_author').agg({'cleaned_text':'count','followers_count':'max',\n",
    "                                         'polarity':'mean','subjectivity':'mean', 'sentiment':pd.Series.mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary.sort_values(by='cleaned_text',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-bridal",
   "metadata": {},
   "source": [
    "Sentiment summary of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped = df_tweet.groupby('sentiment').count()['cleaned_text'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-blair",
   "metadata": {},
   "source": [
    "**Most frequent words in our tweets dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English,Kiny,FR, and Only Tweet or Reply.. Remove Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets=df_tweet.query(\"tweet_category=='Tweet' or tweet_category== 'Reply'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text Preprocessing\n",
    "english_tweets['cleaned_text'] = english_tweets['cleaned_text'].str.lower()\n",
    "english_tweets['cleaned_text'] = english_tweets['cleaned_text'].apply(\n",
    "    lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=' '.join(english_tweets.cleaned_text.values)\n",
    "wordcloud_obj=WordCloud(width=1000,height=600,stopwords=STOPWORDS).generate(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-background",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "fgg=plt.imshow(wordcloud_obj)\n",
    "plt.axis('off')\n",
    "# plt.title('Most Frequent Words In Our Tweets',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgg.figure.savefig('sql_dashboard/cw_rdf.png',bbox_inches='tight',pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-macro",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tweets_df):\n",
    "    # Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['cleaned_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "    #Save only words and excludes emojis, punctuations\n",
    "    word_list_new=[]\n",
    "    for sent in word_list:\n",
    "        word_list_new.append([re.split(r'\\W+',word) for word in sent if word not in STOPWORDS and not word.isdigit()])\n",
    "    \n",
    "    word_list_final=[]\n",
    "    for sent in word_list_new:\n",
    "        word_list_final.append([i[0] for i in sent])\n",
    "    # Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list_final)\n",
    "    corpus_1 = [word_to_id.doc2bow(tweet) for tweet in word_list_final]\n",
    "\n",
    "    return word_list_final, word_to_id, corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, id2word, corpus=preprocess_data(english_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-greensboro",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-niger",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-diamond",
   "metadata": {},
   "source": [
    "**Model 1 words with some digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.857909007134007\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4242327533406264\n",
    "\n",
    "**Model 2 words without digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.82031321033761\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4368570452021986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-cutting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-humor",
   "metadata": {},
   "source": [
    "###  END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-popularity",
   "metadata": {},
   "source": [
    "**Number of Topics optimatization**\n",
    "\n",
    "As we can see the coherence accuracy increases with number of topics which is expected but again \\\n",
    "many topics again would lead to meaningless conclusion. Let's use elbow method to find optimum number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best LDA Model considering different number of topics\n",
    "\n",
    "# params_dic={'topics_number':[],'coherence':[],'perplexity':[]}\n",
    "# for top_number in range(1,10):\n",
    "#     lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                             id2word=id2word,\n",
    "#                                             num_topics=top_number, \n",
    "#                                             random_state=100,\n",
    "#                                             update_every=1,\n",
    "#                                             chunksize=100,\n",
    "#                                             passes=10,\n",
    "#                                             alpha='auto',\n",
    "#                                             per_word_topics=False)\n",
    "    \n",
    "#     perplexity=lda_model.log_perplexity(corpus)  \n",
    "#     # Compute Coherence Score\n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "#     coherence_lda = coherence_model_lda.get_coherence()\n",
    "#     params_dic['topics_number'].append(top_number)\n",
    "#     params_dic['coherence'].append(coherence_lda)\n",
    "#     params_dic['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-auckland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(params_dic).plot(y=['coherence'])\n",
    "# # pd.read_csv(\"elbow_metrics.csv\",index_col=0).plot(y=['coherence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = list(np.arange(0.01, 3, 0.1))\n",
    "# alphas.append('symmetric')\n",
    "# alphas.append('asymmetric')\n",
    "# alphas.append('auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best LDA Model considering different number of alpha\n",
    "\n",
    "# params_dic_alpha={'alpha':[],'coherence':[],'perplexity':[]}\n",
    "# for alpha in alphas:\n",
    "#     lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                             id2word=id2word,\n",
    "#                                             num_topics=7, \n",
    "#                                             random_state=100,\n",
    "#                                             update_every=1,\n",
    "#                                             chunksize=100,\n",
    "#                                             passes=10,\n",
    "#                                             alpha=alpha,\n",
    "#                                             per_word_topics=False)\n",
    "    \n",
    "#     perplexity=lda_model.log_perplexity(corpus)  \n",
    "#     # Compute Coherence Score\n",
    "#     coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "#     coherence_lda = coherence_model_lda.get_coherence()\n",
    "#     params_dic_alpha['alpha'].append(alpha)\n",
    "#     params_dic_alpha['coherence'].append(coherence_lda)\n",
    "#     params_dic_alpha['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(params_dic_alpha).plot(y='coherence')#.sort_values('coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-territory",
   "metadata": {},
   "source": [
    "**Model with selected optimum parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=7, \n",
    "#                                            random_state=100,\n",
    "#                                            update_every=1,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            alpha=0.1,\n",
    "#                                            per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Perplexity\n",
    "# #It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# # doc_lda = lda_model[corpus]\n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "\n",
    "# LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "# LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
