{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "from importlib import reload\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import string\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_tweets_dataframe as cld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-denver",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(cld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from clean_tweets_dataframe import CleanTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=pd.read_csv(\"processed_tweet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner=cld.CleanTweets(df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-fantasy",
   "metadata": {},
   "source": [
    "**Using cleaner module from clean_tweets_dataframe to clean the imported dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet=cleaner.drop_unwanted_column(df_tweet)\n",
    "df_tweet=cleaner.drop_duplicate(df_tweet)\n",
    "df_tweet=cleaner.convert_to_datetime(df_tweet)\n",
    "df_tweet=cleaner.convert_to_numbers(df_tweet)\n",
    "df_tweet=cleaner.remove_other_languages_tweets(df_tweet)\n",
    "df_tweet=cleaner.treat_special_characters(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-boost",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_tweet.shape)\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "federal-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en      619\n",
       "fr      183\n",
       "kiny     52\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-colombia",
   "metadata": {},
   "source": [
    "###  Export french tweets, make translation and insert back new translated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hispanic-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans=df_tweet.query(\"lang=='fr'| lang =='kiny'\")[['original_text','cleaned_text','lang']]\n",
    "df_trans.to_csv('df_to_translate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sixth-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "combined-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_translate=df_tweet.query(\"lang=='fr'| lang =='kiny'\")['cleaned_text'].to_dict()\n",
    "\n",
    "dict_translated=pd.read_csv('df_translated.csv',index_col=0,usecols=[0,4]).to_dict()['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thirty-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_to_translate.keys():\n",
    "    df_tweet.loc[idx, 'cleaned_text'] = dict_translated[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "whole-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "violent-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dict_translated.keys():\n",
    "    blob = TextBlob(dict_translated[idx])\n",
    "    pol=blob.sentiment.polarity\n",
    "    df_tweet.loc[idx, 'sentiment'] = 'Positive' if pol>0 else ('Negative' if pol < 0 else 'Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-reset",
   "metadata": {},
   "source": [
    "#### Save new dataframe for dashboard creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ranking-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.to_csv('sql_dashboard/processed_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-rating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "competent-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mostflwd=df_tweet[['original_author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "rural-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mostflwd['hh']=d_mostflwd['original_author'].apply(lambda x : '['+x+']'+'(https://twitter.com/'+str(x)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dying-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_author</th>\n",
       "      <th>hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nduwamungu5</td>\n",
       "      <td>[Nduwamungu5](https://twitter.com/Nduwamungu5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EUwatchers</td>\n",
       "      <td>[EUwatchers](https://twitter.com/EUwatchers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>123_INFO_DE</td>\n",
       "      <td>[123_INFO_DE](https://twitter.com/123_INFO_DE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AriaSoondingie</td>\n",
       "      <td>[AriaSoondingie](https://twitter.com/AriaSoond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arson_cole</td>\n",
       "      <td>[arson_cole](https://twitter.com/arson_cole)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10344</th>\n",
       "      <td>ngoyikabongo1</td>\n",
       "      <td>[ngoyikabongo1](https://twitter.com/ngoyikabon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>egonwillighagen</td>\n",
       "      <td>[egonwillighagen](https://twitter.com/egonwill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>iamdedit</td>\n",
       "      <td>[iamdedit](https://twitter.com/iamdedit)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>steverukundo</td>\n",
       "      <td>[steverukundo](https://twitter.com/steverukundo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>kimjimpaul</td>\n",
       "      <td>[kimjimpaul](https://twitter.com/kimjimpaul)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>854 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_author                                                 hh\n",
       "8          Nduwamungu5     [Nduwamungu5](https://twitter.com/Nduwamungu5)\n",
       "9           EUwatchers       [EUwatchers](https://twitter.com/EUwatchers)\n",
       "17         123_INFO_DE     [123_INFO_DE](https://twitter.com/123_INFO_DE)\n",
       "18      AriaSoondingie  [AriaSoondingie](https://twitter.com/AriaSoond...\n",
       "19          arson_cole       [arson_cole](https://twitter.com/arson_cole)\n",
       "...                ...                                                ...\n",
       "10344    ngoyikabongo1  [ngoyikabongo1](https://twitter.com/ngoyikabon...\n",
       "10371  egonwillighagen  [egonwillighagen](https://twitter.com/egonwill...\n",
       "10384         iamdedit           [iamdedit](https://twitter.com/iamdedit)\n",
       "10394     steverukundo   [steverukundo](https://twitter.com/steverukundo)\n",
       "10401       kimjimpaul       [kimjimpaul](https://twitter.com/kimjimpaul)\n",
       "\n",
       "[854 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_mostflwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-foundation",
   "metadata": {},
   "source": [
    "### EDA of Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in every column\n",
    "ax = df_tweet.isna().sum().sort_values().plot(kind = 'barh', figsize = (7, 9))\n",
    "plt.title('Percentage of Missing Values Per Column in Tweets data', fontdict={'size':15})\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage ='{:,.3f}%'.format((p.get_width()/df_tweet.shape[0])*100)\n",
    "    width, height =p.get_width(),p.get_height()\n",
    "    x=p.get_x()+width+0.02\n",
    "    y=p.get_y()+height/2\n",
    "    ax.annotate(percentage,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-knight",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tweet['place'].value_counts(sort=True, ascending=False)[:10].plot(kind='barh',\n",
    "                                                                     figsize=(12,5),xlabel='Place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date=df_tweet.set_index('created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_date.resample('D').mean()[['polarity','subjectivity']].dropna().plot(figsize=(10,6),xlabel='Date,time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-grenada",
   "metadata": {},
   "source": [
    "### uni-variate Analysis on Hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df=df_tweet[['original_text','hashtags','retweet_hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hashtags(df_tweet):\n",
    "    '''This function will extract hashtags'''\n",
    "    return re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', df_tweet)\n",
    "\n",
    "hashtag_df['hashtag_check']=df_tweet.original_text.apply(find_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df.dropna(subset=['hashtag_check'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list=list(hashtag_df['hashtag_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df = pd.DataFrame([tag for tags_row in tags_list for tag in tags_row],columns=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Actual Hashtags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert hastags to lowercase\n",
    "hashtags_list_df['hashtag'] = hashtags_list_df['hashtag'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=hashtags_list_df.value_counts()[:10].plot(kind='bar',figsize=(12,5),xlabel='Hashtags in Lowercase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary=df_tweet.groupby('original_author').agg({'cleaned_text':'count','followers_count':'max',\n",
    "                                         'polarity':'mean','subjectivity':'mean', 'sentiment':pd.Series.mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_summary.sort_values(by='cleaned_text',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-bridal",
   "metadata": {},
   "source": [
    "Sentiment summary of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped = df_tweet.groupby('sentiment').count()['cleaned_text'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=df_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-blair",
   "metadata": {},
   "source": [
    "**Most frequent words in our tweets dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets=cleaner.remove_other_languages_tweets(df_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text Preprocessing\n",
    "english_tweets['cleaned_text'] = english_tweets['cleaned_text'].str.lower()\n",
    "english_tweets['cleaned_text'] = english_tweets['cleaned_text'].apply(\n",
    "    lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=' '.join(english_tweets.cleaned_text.values)\n",
    "wordcloud_obj=WordCloud(width=1000,height=600,stopwords=STOPWORDS).generate(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-background",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "fgg=plt.imshow(wordcloud_obj)\n",
    "plt.axis('off')\n",
    "# plt.title('Most Frequent Words In Our Tweets',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgg.figure.savefig('sql_dashboard/cw_rdf.png',bbox_inches='tight',pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-macro",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tweets_df):\n",
    "    # Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['cleaned_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "    #Save only words and excludes emojis, punctuations\n",
    "    word_list_new=[]\n",
    "    for sent in word_list:\n",
    "        word_list_new.append([re.split(r'\\W+',word) for word in sent if word not in STOPWORDS and not word.isdigit()])\n",
    "    \n",
    "    word_list_final=[]\n",
    "    for sent in word_list_new:\n",
    "        word_list_final.append([i[0] for i in sent])\n",
    "    # Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list_final)\n",
    "    corpus_1 = [word_to_id.doc2bow(tweet) for tweet in word_list_final]\n",
    "\n",
    "    return word_list_final, word_to_id, corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, id2word, corpus=preprocess_data(english_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-greensboro",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-niger",
   "metadata": {},
   "source": [
    "### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-diamond",
   "metadata": {},
   "source": [
    "**Model 1 words with some digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.857909007134007\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4242327533406264\n",
    "\n",
    "**Model 2 words without digits, 5 topics**\n",
    "\n",
    "Perplexity:  -9.82031321033761\\\n",
    "Ldamodel Coherence Score/Accuracy on Tweets:  0.4368570452021986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-cutting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-popularity",
   "metadata": {},
   "source": [
    "**Number of Topics optimatization**\n",
    "\n",
    "As we can see the coherence accuracy increases with number of topics which is expected but again \\\n",
    "many topics again would lead to meaningless conclusion. Let's use elbow method to find optimum number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best LDA Model considering different number of topics\n",
    "\n",
    "params_dic={'topics_number':[],'coherence':[],'perplexity':[]}\n",
    "for top_number in range(1,10):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=top_number, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=False)\n",
    "    \n",
    "    perplexity=lda_model.log_perplexity(corpus)  \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    params_dic['topics_number'].append(top_number)\n",
    "    params_dic['coherence'].append(coherence_lda)\n",
    "    params_dic['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-auckland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(params_dic).plot(y=['coherence'])\n",
    "# pd.read_csv(\"elbow_metrics.csv\",index_col=0).plot(y=['coherence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-victor",
   "metadata": {},
   "source": [
    "###  END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-backing",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "silent-snowboard",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "harmful-debate",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "supported-pound",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = list(np.arange(0.01, 3, 0.1))\n",
    "alphas.append('symmetric')\n",
    "alphas.append('asymmetric')\n",
    "alphas.append('auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best LDA Model considering different number of alpha\n",
    "\n",
    "params_dic_alpha={'alpha':[],'coherence':[],'perplexity':[]}\n",
    "for alpha in alphas:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=7, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha=alpha,\n",
    "                                            per_word_topics=False)\n",
    "    \n",
    "    perplexity=lda_model.log_perplexity(corpus)  \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    params_dic_alpha['alpha'].append(alpha)\n",
    "    params_dic_alpha['coherence'].append(coherence_lda)\n",
    "    params_dic_alpha['perplexity'].append(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(params_dic_alpha).plot(y='coherence')#.sort_values('coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-territory",
   "metadata": {},
   "source": [
    "**Model with selected optimum parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.1,\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
